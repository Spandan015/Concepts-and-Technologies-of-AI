{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPQijvQGHTOL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class CustomDecisionTree:\n",
        "    def __init__(self, max_depth=None):\n",
        "        self.max_depth = max_depth\n",
        "        self.tree = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # Ensure inputs are NumPy arrays\n",
        "        X = np.array(X)\n",
        "        y = np.array(y)\n",
        "        self.tree = self._build_tree(X, y)\n",
        "\n",
        "    def _build_tree(self, X, y, depth=0):\n",
        "        num_samples, num_features = X.shape\n",
        "        unique_classes = np.unique(y)\n",
        "\n",
        "        # Stopping criteria\n",
        "        if len(unique_classes) == 1 or (self.max_depth is not None and depth >= self.max_depth):\n",
        "            return {'class': unique_classes[0]}\n",
        "\n",
        "        best_info_gain, best_split = -1, None\n",
        "\n",
        "        for feature_idx in range(num_features):\n",
        "            thresholds = np.unique(X[:, feature_idx])\n",
        "            for threshold in thresholds:\n",
        "                left_mask = X[:, feature_idx] <= threshold\n",
        "                right_mask = ~left_mask\n",
        "                if len(np.unique(y[left_mask])) == 0 or len(np.unique(y[right_mask])) == 0:\n",
        "                    continue\n",
        "                info_gain = self._information_gain(y, y[left_mask], y[right_mask])\n",
        "                if info_gain > best_info_gain:\n",
        "                    best_info_gain = info_gain\n",
        "                    best_split = {\n",
        "                        'feature_idx': feature_idx,\n",
        "                        'threshold': threshold,\n",
        "                        'left_indices': left_mask,\n",
        "                        'right_indices': right_mask\n",
        "                    }\n",
        "\n",
        "        if best_split is None:\n",
        "            return {'class': np.bincount(y).argmax()}\n",
        "\n",
        "        left_tree = self._build_tree(X[best_split['left_indices']], y[best_split['left_indices']], depth + 1)\n",
        "        right_tree = self._build_tree(X[best_split['right_indices']], y[best_split['right_indices']], depth + 1)\n",
        "\n",
        "        return {'feature_idx': best_split['feature_idx'],\n",
        "                'threshold': best_split['threshold'],\n",
        "                'left': left_tree,\n",
        "                'right': right_tree}\n",
        "\n",
        "    def _information_gain(self, parent, left, right):\n",
        "        prob_left = len(left) / len(parent)\n",
        "        prob_right = len(right) / len(parent)\n",
        "        return self._entropy(parent) - (prob_left * self._entropy(left) + prob_right * self._entropy(right))\n",
        "\n",
        "    def _entropy(self, y):\n",
        "        hist = np.bincount(y)\n",
        "        ps = hist / len(y)\n",
        "        return -np.sum([p * np.log2(p) for p in ps if p > 0])\n",
        "\n",
        "    def predict(self, X):\n",
        "        return [self._traverse_tree(x, self.tree) for x in np.array(X)]\n",
        "\n",
        "    def _traverse_tree(self, x, tree):\n",
        "        if 'class' in tree:\n",
        "            return tree['class']\n",
        "        feature_value = x[tree['feature_idx']]\n",
        "        branch = tree['left'] if feature_value <= tree['threshold'] else tree['right']\n",
        "        return self._traverse_tree(x, branch)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset from CSV\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/Concepts and Technology of AI/IRIS.csv\")\n",
        "\n",
        "# Separate features and target\n",
        "X = data.iloc[:, :-1]  # All columns except the last one\n",
        "y = data.iloc[:, -1]   # The last column (assumed to be the target)\n",
        "\n",
        "# Encode target labels into numeric values\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split into training and test sets (70% training, 30% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "Y93KaDyiHw-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#####. Step -3- Train and Evaluate a Custom Decision Tree:\n",
        "X_train_np = X_train.to_numpy()\n",
        "X_test_np = X_test.to_numpy()\n",
        "y_train_np = y_train  # Already numeric\n",
        "y_test_np = y_test    # Already numeric\n",
        "\n",
        "# Train the custom decision tree\n",
        "custom_tree = CustomDecisionTree(max_depth=3)\n",
        "custom_tree.fit(X_train_np, y_train_np)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_custom = custom_tree.predict(X_test_np)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_custom = accuracy_score(y_test_np, y_pred_custom)\n",
        "print(f\"Custom Decision Tree Accuracy: {accuracy_custom:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7qo8pLILely",
        "outputId": "30a70a41-25f8-4076-b8b8-5045ad4ad0f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom Decision Tree Accuracy: 0.8444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######. Step -4- Train and Evaluate a Scikit Learn Decision Tree:\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "sklearn_tree = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "sklearn_tree.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_sklearn = sklearn_tree.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_sklearn = accuracy_score(y_test, y_pred_sklearn)\n",
        "print(f\"Scikit-learn Decision Tree Accuracy: {accuracy_sklearn:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AJnfCSEIpue",
        "outputId": "059a70c5-843c-4a9d-bcc8-48c22be53ae8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scikit-learn Decision Tree Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy Comparison:\")\n",
        "print(f\"Custom Decision Tree Accuracy: {accuracy_custom:.4f}\")\n",
        "print(f\"Scikit-learn Decision Tree Accuracy: {accuracy_sklearn:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4vwMkoIKkio",
        "outputId": "a8806446-4d65-4f1f-d98a-b028827c4bb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Comparison:\n",
            "Custom Decision Tree Accuracy: 0.8444\n",
            "Scikit-learn Decision Tree Accuracy: 1.0000\n"
          ]
        }
      ]
    }
  ]
}